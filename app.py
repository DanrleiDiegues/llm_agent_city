__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import pandas as pd
import google.generativeai as genai
import chromadb
from chromadb import Documents, EmbeddingFunction, Embeddings
from google.api_core import retry
import os
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Configurar a p√°gina
st.set_page_config(
    page_title="Chatbot Ch√°cara-MG",
    page_icon="üèòÔ∏è",
    layout="centered"
)

# Classe de embedding (mesma que voc√™ j√° tem)
class GeminiEmbeddingFunction(EmbeddingFunction):
    document_mode = True

    def __call__(self, input: Documents) -> Embeddings:
        embedding_task = "retrieval_document" if self.document_mode else "retrieval_query"
        retry_policy = {"retry": retry.Retry(predicate=retry.if_transient_error)}
        
        response = genai.embed_content(
            model="models/text-embedding-004",
            content=input,
            task_type=embedding_task,
            request_options=retry_policy,
        )
        return response["embedding"]

# Fun√ß√£o para carregar dados
@st.cache_resource
def load_knowledge_base():
    data = pd.read_csv("data/ch√°cara_knowledge.csv", 
                      encoding='latin1',
                      sep=',',
                      quotechar='"',
                      escapechar='\\',
                      on_bad_lines='warn')
    return data

# Fun√ß√£o para inicializar ChromaDB
@st.cache_resource
def init_chromadb():
    embed_fn = GeminiEmbeddingFunction()
    
    # Usar o novo cliente persistente
    #chroma_client = chromadb.PersistentClient(path="./chroma_db")
    
    # Usar o cliente em mem√≥ria
    chroma_client = chromadb.Client()
    
    db = chroma_client.get_or_create_collection(
        name="characadb",
        embedding_function=embed_fn
    )
    
    # Carregar documentos se o DB estiver vazio
    if db.count() == 0:
        data = load_knowledge_base()
        documents = data['Conte√É¬∫do'].tolist()
        db.add(
            documents=documents,
            ids=[str(i) for i in range(len(documents))]
        )
    
    return db, embed_fn

# Inicializar o modelo Gemini
@st.cache_resource
def init_model():
    SYSTEM_MESSAGE = '''Voc√™ √© um agente especializado em dar informa√ß√µes sobre a cidade Ch√°cara em Minas Gerais.
    Voc√™ √© um agente que responde sobre quest√µes hist√≥ricas, culturais e geografia. 
    Voc√™ n√£o responder√° quest√µes que n√£o sejam sobre ch√°cara e caso algu√©m pergunte, 
    voc√™ responder√° educadamente que n√£o pode dar estas informa√ß√µes.
    '''
    
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash-latest",
        system_instruction=SYSTEM_MESSAGE
    )
    
    chat = model.start_chat(
        history=[
            {"role": "user", "parts": "Hello"},
            {"role": "model", "parts": "Great to meet you. What would you like to know?"},
        ]
    )
    
    return chat


# Interface principal
def main():
    
    st.title("üèòÔ∏è Chatbot Ch√°cara-MG")
    
    # Adicionar exemplos de perguntas antes do chat input
    st.markdown("""
    ### Exemplos de perguntas que voc√™ pode fazer:
    - üèõÔ∏è "Qual √© a hist√≥ria de Ch√°cara?"
    - üöå "Quais os hor√°rios de √¥nibus de CH vs. JF durante a semana de manh√£?"
    - üåç "Me fale sobre a geografia da cidade.."
    - üé≠ "Quais s√£o as principais festas da cidade?"
    - üë• "Quantos habitantes tem Ch√°cara?"
    - üçΩÔ∏è "Quais os restaurantes da cidade?"
    """)
    
    # Se√ß√£o expans√≠vel com exemplos
    with st.expander("üìù Clique aqui para ver exemplos de perguntas"):
        st.markdown("""
        ### Temas que voc√™ pode explorar:
        
        **Hist√≥ria e Cultura:**
        - Hist√≥ria da funda√ß√£o da cidade
        - Origem do nome
        - Tradi√ß√µes locais
        
        **Geografia e Demografia:**
        - Localiza√ß√£o
        - Popula√ß√£o
        - Clima
        
        **Turismo:**
        - Pontos tur√≠sticos
        - Festas tradicionais
        - Gastronomia local
        
        **Economia:**
        - Principais atividades econ√¥micas
        - Produtos locais
        - Com√©rcio
        """)
    
    # Inicializar componentes
    db, embed_fn = init_chromadb()
    chat = init_model()
    
    # Inicializar hist√≥rico de chat no session state
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Mostrar hist√≥rico de mensagens
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input do usu√°rio
    if prompt := st.chat_input("Fa√ßa sua pergunta sobre Ch√°cara-MG"):
        # Adicionar pergunta ao hist√≥rico
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                # Buscar contexto relevante
                embed_fn.document_mode = False
                result = db.query(
                    query_texts=[prompt],
                    n_results=2
                )
                context = "\n".join(result["documents"][0])
                
                # Criar query aumentada
                augmented_query = f"""
                Contexto: {context}
                
                Pergunta do usu√°rio: {prompt}
                
                Por favor, responda √† pergunta usando as informa√ß√µes do contexto acima.
                """
                
                # Gerar resposta
                response = chat.send_message(augmented_query)
                st.markdown(response.text)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append(
                    {"role": "assistant", "content": response.text}
                )

    # Sidebar com informa√ß√µes
    with st.sidebar:
        st.markdown("### Sobre")
        st.write("Este chatbot utiliza RAG (Retrieval-Augmented Generation) para fornecer informa√ß√µes precisas sobre a cidade de Ch√°cara-MG.")
        
        if st.button("Limpar Conversa"):
            st.session_state.messages = []
            st.rerun()
            
        

if __name__ == "__main__":
    main()