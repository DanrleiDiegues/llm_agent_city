import streamlit as st
import pandas as pd
import google.generativeai as genai
import chromadb
from chromadb.api.types import EmbeddingFunction, Documents, Embeddings  # Corre√ß√£o aqui
from chromadb.config import Settings
from google.api_core import retry
import os
from dotenv import load_dotenv

# Verifica se a chave da API do Google est√° configurada
if not os.getenv("GOOGLE_API_KEY"):
    st.error("Chave da API do Google n√£o encontrada. Por favor, configure a vari√°vel de ambiente GOOGLE_API_KEY.")
    st.stop()


# Carregar vari√°veis de ambiente
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Configurar a p√°gina
st.set_page_config(
    page_title="Chatbot Ch√°cara-MG",
    page_icon="üèòÔ∏è",
    layout="centered"
)

# Classe de embedding (mesma que voc√™ j√° tem)
class GeminiEmbeddingFunction(EmbeddingFunction):
    document_mode = True

    def __call__(self, input: Documents) -> Embeddings:
        embedding_task = "retrieval_document" if self.document_mode else "retrieval_query"
        retry_policy = retry.Retry(predicate=retry.if_transient_error)
        
        # Garantir que input seja uma lista
        if isinstance(input, str):
            input = [input]
        
        try:
            response = genai.embed_content(
                model="models/text-embedding-004",
                content=input,
                task_type=embedding_task,
                request_options={"retry": retry_policy},
            )
            # Verificar se temos uma lista de embeddings ou um √∫nico embedding
            embeddings = response["embedding"]
            if not isinstance(embeddings[0], list):
                embeddings = [embeddings]
            return embeddings
        except Exception as e:
            st.error(f"Erro ao gerar embedding: {str(e)}")
            # Retornar embedding vazio em caso de erro
            return [[0.0] * 768] * len(input)

# Fun√ß√£o para carregar dados
@st.cache_resource
def load_knowledge_base():
    try:
        data = pd.read_csv("data/ch√°cara_knowledge.csv", 
                          encoding='latin1',
                          sep=',',
                          quotechar='"',
                          escapechar='\\',
                          on_bad_lines='warn')
        return data
    except Exception as e:
        st.error(f"Erro ao carregar base de conhecimento: {str(e)}")
        # Retornar DataFrame vazio em caso de erro
        return pd.DataFrame(columns=['Conte√É¬∫do'])

# Fun√ß√£o para inicializar ChromaDB
@st.cache_resource
def init_chromadb():
    embed_fn = GeminiEmbeddingFunction()
    
    # Usar cliente ef√™mero para evitar problemas de persist√™ncia no Streamlit Cloud
    chroma_client = chromadb.EphemeralClient()
    
    db = chroma_client.get_or_create_collection(
        name="characa_db",
        embedding_function=embed_fn
    )
    
    # Carregar documentos sempre (j√° que estamos usando cliente ef√™mero)
    data = load_knowledge_base()
    documents = data['Conte√É¬∫do'].tolist()
    db.add(
        documents=documents,
        ids=[str(i) for i in range(len(documents))]
    )
    
    return db, embed_fn

# Inicializar o modelo Gemini
@st.cache_resource
def init_model():
    SYSTEM_MESSAGE = '''Voc√™ √© um agente especializado em dar informa√ß√µes sobre a cidade Ch√°cara em Minas Gerais.
    Voc√™ √© um agente que responde sobre quest√µes hist√≥ricas, culturais e geografia. 
    Voc√™ n√£o responder√° quest√µes que n√£o sejam sobre ch√°cara e caso algu√©m pergunte, 
    voc√™ responder√° educadamente que n√£o pode dar estas informa√ß√µes.
    '''
    
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash-latest",
        system_instruction=SYSTEM_MESSAGE
    )
    
    chat = model.start_chat(
        history=[
            {"role": "user", "parts": "Hello"},
            {"role": "model", "parts": "Great to meet you. What would you like to know?"},
        ]
    )
    
    return chat


# Interface principal
def main():
    
    st.title("üèòÔ∏è Chatbot Ch√°cara-MG")
    
    # Inicializar componentes
    db, embed_fn = init_chromadb()
    chat = init_model()
    
    # Inicializar hist√≥rico de chat no session state
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Mostrar hist√≥rico de mensagens
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input do usu√°rio
    if prompt := st.chat_input("Fa√ßa sua pergunta sobre Ch√°cara-MG"):
        # Adicionar pergunta ao hist√≥rico
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                # Buscar contexto relevante
                embed_fn.document_mode = False
                result = db.query(
                    query_texts=[prompt],
                    n_results=2
                )
                context = "\n".join(result["documents"][0])
                
                # Criar query aumentada
                augmented_query = f"""
                Contexto: {context}
                
                Pergunta do usu√°rio: {prompt}
                
                Por favor, responda √† pergunta usando as informa√ß√µes do contexto acima.
                """
                
                # Gerar resposta
                response = chat.send_message(augmented_query)
                st.markdown(response.text)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append(
                    {"role": "assistant", "content": response.text}
                )

    # Sidebar com informa√ß√µes
    with st.sidebar:
        st.markdown("### Sobre")
        st.write("Este chatbot utiliza RAG (Retrieval-Augmented Generation) para fornecer informa√ß√µes precisas sobre a cidade de Ch√°cara-MG.")
        
        if st.button("Limpar Conversa"):
            st.session_state.messages = []
            st.rerun()
            
        # Adicionar exemplos de perguntas antes do chat input
        st.markdown("""
        ### Exemplos de perguntas que voc√™ pode fazer:
        - üèõÔ∏è "Qual √© a hist√≥ria de Ch√°cara?"
        - üìç "Onde fica Ch√°cara?"
        - üé≠ "Quais s√£o as principais festas da cidade?"
        - üë• "Quantos habitantes tem Ch√°cara?"
        - üè∫ "Quais s√£o os pontos tur√≠sticos?"
        """)
        
        # Se√ß√£o expans√≠vel com exemplos
        with st.expander("üìù Clique aqui para ver exemplos de perguntas"):
            st.markdown("""
            ### Temas que voc√™ pode explorar:
            
            **Hist√≥ria e Cultura:**
            - Hist√≥ria da funda√ß√£o da cidade
            - Origem do nome
            - Tradi√ß√µes locais
            
            **Geografia e Demografia:**
            - Localiza√ß√£o
            - Popula√ß√£o
            - Clima
            
            **Turismo:**
            - Pontos tur√≠sticos
            - Festas tradicionais
            - Gastronomia local
            
            **Economia:**
            - Principais atividades econ√¥micas
            - Produtos locais
            - Com√©rcio
            """)

if __name__ == "__main__":
    main()